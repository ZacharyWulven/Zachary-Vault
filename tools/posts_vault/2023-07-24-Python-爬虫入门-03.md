---
layout: post
title: Python-爬虫入门-03
date: 2023-07-24 16:45:30.000000000 +09:00
categories: [Python, 爬虫]
tags: [Python, 爬虫]
---

# 20 Selenium

## Selenium 简介
* Selenium 是一个用于 web 应用程序的测试工具
* Selenium 测试测试直接运行在浏览器中，就像真正的用户操作一样
* 支持各种 driver 驱动真实浏览器完成测试
* 支持无界面浏览器操作

## 为什么学习 Selenium
* 让 Selenium 驱动一个真实的浏览器，然后给我们获取数据

## Selenium 安装
1. [下载谷歌浏览器驱动](http://chromedriver.storage.googleapis.com/index.html)
* 下载驱动的版本最好与当前浏览器版本一致，例如 `114.0.5735.248`，下载 `114.0.` 的都行。或下载更高的版本
* 下载后，将解压的 chromedriver 可执行文件放到代码爬虫代码的同级目录下
2. install selenium

```bash
$ pip3 install selenium
```

## Selenium 基本使用


```python
# 1 导入 selenium
from selenium import webdriver

import time

# 2 创建浏览器操作对象
# 即下载的 chromedriver 驱动的路径
# path = 'chromedriver'
# print(path)

browser = webdriver.Chrome()

# 3 访问网站
url = 'https://www.com'
browser.get(url)

content = browser.page_source
print(content)

# sleep 300s 防止自动关闭
time.sleep(300)
```

## Selenium 元素定位
* 模拟鼠标和键盘来操作这些元素，如点击、输入等。操作这些元素前我们要先找到他们，webdriver 提供了很多定位的方法


```python
from selenium import webdriver
import time

url = 'https://'

browser = webdriver.Chrome()
browser.get(url)

# 元素定位

# 1 根据 id 的值，找到对象 （常用）
# 这里是找 id 属性，value 为 su 的对象
button = browser.find_element('id', 'su')
print(button)

# 2根据 标签的属性的属性值，找到对象
# 这里是找 name 属性，value 为 wd 的对象
button = browser.find_element('name', 'wd')
print(button)

# 3 根据 xpath 语句获取对象 （常用）
# button = browser.find_elements('xpath', '//input[@id="su"]')[0]
button = browser.find_element('xpath', '//input[@id="su"]')
print(button)


# 4 根据 标签名称 获取对象
# 这里获取 input 标签的对象
button = browser.find_element('tag name', 'input')
print(button)

# 5 根据 BeautifulSoup 语法获取对象 （常用）
# 这里获取 id=su 的对象
button = browser.find_element('css selector', '#su')
print(button)

# 6 根据 链接的文本 获取对象
button = browser.find_element('link text', '视频')
print(button)
```

## Selenium 元素信息

```python
from selenium import webdriver


url = 'https://w'

# options = webdriver.ChromeOptions()
# options.add_argument('--no-sandbox')

browser = webdriver.Chrome()
browser.get(url)

input_ = browser.find_element('id', 'su')

# 获取 class 属性值
cls = input_.get_attribute('class')
print(cls)

# 获取 标签名称
print(input_.tag_name)

# 获取元素文本
a = browser.find_element('link text', '新闻')
print(a.text)
```

> 如果报错 `unknown error devtoolsactiveport file doesn't exist` 可删除 `~/.cache/selenium` 文件夹即可
{: .prompt-info }

## Selenium 交互


```python
from selenium import webdriver

import time

url = 'https://.com'


browser = webdriver.Chrome()
browser.get(url)


time.sleep(2)

# 获得输入框对象
input_ = browser.find_element('id', 'kw')
print(input_)

# 在输入框中输入 搜索的关键字
input_.send_keys('明星')

time.sleep(2)

# 获取按钮

button = browser.find_element('id', 'su')
# 点击按钮
button.click()

time.sleep(2)

# 滑动到底部
# scrollTop 滑动到底部，value（距离） 是 10 万
js_to_bottom = 'document.documentElement.scrollTop=100000'
browser.execute_script(js_to_bottom)
time.sleep(2)

# 获取下一页按钮
next_btn = browser.find_element('xpath', '//a[@class="n"]')
print(f'next btn {next_btn}')
next_btn.click()

time.sleep(2)

browser.execute_script(js_to_bottom)

time.sleep(2)

# 回到上一页
browser.back()
browser.execute_script(js_to_bottom)

time.sleep(2)

# 回去
browser.forward()
time.sleep(2)

browser.execute_script(js_to_bottom)

time.sleep(2)
```


## 无界面的浏览器
* 支持页面元素查找、js 执行等
* 由于不进行 css 和 gui 渲染，所以运行效率比真实浏览器要快
* 目前有俩
1. Phantomjs（公司黄了🤣，新版本 selenium 已经不支持了，如果想用可以使用低版本的 selenium）
2. Chrome handless (推荐)

### Chrome handless
* Chrome-headless 模式，可以让你不打开 UI 界面的情况下使用 Chrome


```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options


def shared_browser():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    # 试了一下不写这个也能用
    # chrome_options.binary_location = r'~/Applications'
    browser = webdriver.Chrome(options=options)
    return browser


browser = shared_browser()
url = ''

browser.get(url)
print('url')

browser.save_screenshot('screenshot.png')
```

# 21 Request 库

## 文档

* [官方文档](https://requests.readthedocs.io/projects/cn/zh_CN/latest/)
* [快速上手](https://requests.readthedocs.io/projects/cn/zh_CN/latest/user/quickstart.html)

## 安装

```bash
$ pip3 install requests
```


## 基本使用

```python
import requests


url = ''

response = requests.get(url)

# 一个类型和六个属性
# 类型是 requests.models.Response
print(type(response))

# 1 设置 response 的编码格式
response.encoding = 'utf-8'

# 2 以字符串形式返回网页的源码
print(response.text)

# 3 返回请求的 url
print(response.url)

# 4 返回的是二进制的数据，用的不多，用 text 能替代
print(response.content)

# 5 返回响应的状态码
print(response.status_code)

# 6 返回 headers
print(response.headers)
```

## get 请求
* 参数使用 params 传递
* 参数无需 urlencode 编码
* 不需要请求对象定制
* 请求路径中 query 前的 ? 可加也可不加


```python
import requests
import urllib.request


url = 'https://?'

headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac'
}

data = {
    'xx': '北京',
}

# url 请求路径
# params 即参数
# kwargs 字典
resp = requests.get(url=url, params=data, headers=headers)

content = resp.text
print(content)
```

## post 请求
* post 请求不需要编解码
* post 请求的参数是 data
* 不需要请求对象的定制


```python
import requests


url = ''

headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}

# post 请求的参数，必须进行编码，即必须使用 urlencode
data = {
    'xx': 'spider'
}

# url 请求地址
# data 请求参数
# kwargs 字典
resp = requests.post(url=url, data=data, headers=headers)
content = resp.text
print(content)
```

## 代理

```python
import requests

url = 'http?'


headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}

data = {
    'xx': 'ip'
}

proxies = {
    'http': '182.34.102.138:9999'
}

resp = requests.get(url=url, params=data, headers=headers, proxies=proxies)
text = resp.text
print(text)
```

## cookie 登录 验证码

### 难点
1. 如何找登录接口
* 方法 1：给一个错误的密码，在开发者工具中找
* 方法 2：如果 chrome 版本过低，需要把开发者工具中，preserve log 勾上，不勾的话可能登录后其接口 log 就被删除了。但勾上可能接口太多，所以推荐方法一
2. 隐藏域：登录接口中的 post 参数为网页源码中的隐藏域，特征为标签的属性 type 为隐藏，例如 `<input type="hidden"`
3. 验证码：保证始终是一个请求，要点是 `使用同一个请求的 session()，完成后续工作`
* 获取验证码图片时候要保证请求跟之前获取网页时同一个，即需要使用上一个请求的 session()，而不是再 requests
* 登录时候也不能使用 requests，也要使用上一个请求的 session()


```python
import requests
from lxml import etree
import urllib.request


# 通过登录 进入页面

# 通过找登录接口发现，需要的
# __VIEWSTATE: oDcXaUXRxOCFJijd9bXX7NhNBNUxAGnzbxk4XOq715LrQpUCg=
# __VIEWSTATEGENERATOR: C93BE1AE
# from: http://
# email: 
# pwd: aaa111111
# code: 
# denglu: 登录

# 我们观察到 __VIEWSTATE、__VIEWSTATEGENERATOR、code 是可变化的
# 难点 1： __VIEWSTATE、__VIEWSTATEGENERATOR，一般看不到的数据可以在页面的源代码中找到
# 我们观察到这俩数据在页面的源码中，然后进行解析就可以获取
# 源码中的 <input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="pM5feH9xR3IXHSEUqlg+4Ap6ovm+H0xD1LeR55W=">
# type="hidden" 说明是隐藏域，一般大的网站可能都有隐藏域，这也是一种反爬手段
#
# 难度 2：验证码 code

# 登录页面 url

headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}

login_url = ''

login_resp = requests.get(url=login_url, headers=headers)
login_content = login_resp.text
print(login_content)

login_tree = etree.HTML(login_content)
print(f'login_tree is {login_tree}')

# get __VIEWSTATE
view_state = login_tree.xpath('//input[@id="__VIEWSTATE"]/@value')[0]
print(f'view_state is {view_state}')

# get __VIEWSTATEGENERATOR
view_state_generator = login_tree.xpath('//input[@id="__VIEWSTATEGENERATOR"]/@value')[0]
print(f'view_state_generator is {view_state_generator}')

# 获取验证码图片
code = login_tree.xpath('//img[@id="imgCode"]/@src')[0]
print(code)
code_url = '' + code
print(code_url)

# 有坑：即你在 urlretrieve 验证码就变了 就不是第一次打开页面时候的验证码了
# urllib.request.urlretrieve(url=code_url, filename='code.jpg')
#
# 那怎么解决呢 ：？
# requests 里有一个方法叫 session()，通过 session 的返回值就能使请求变为一个对象
session = requests.session()
# 验证码的 url 内容
code_resp = session.get(code_url)
# 注意此时要使用二进制数据, 因为我们要图片下载，图片下载要使用二进制
code_content = code_resp.content
# wb 模式就是将二进制写入文件
with open('code.jpg', 'wb') as fp:
    fp.write(code_content)


# 获取验证码的图片后下载到本地，然后观察验证码，观察后在控制台输入这个验证码
# 然后把这个值给 code 就可以登录了
code_name = input('请输入你的验证码')

# 如何找登录接口
# 方法 1：给一个错误的密码，在开发者工具中找
# 方法 2：如果 chrome 版本过低，需要把开发者工具中，preserve log 勾上，不勾的话可能登录后其接口 log 就被删除了

url = ''

data = {
    '__VIEWSTATE': view_state,
    '__VIEWSTATEGENERATOR': view_state_generator,
    'from': 'http://',
    'email': ,
    'pwd': '',
    'code': code_name,
    'denglu': '登录',
}

# 这里也不能用 requests 要用 session 要保证是同一个请求
# resp = requests.post(url=url, data=data, headers=headers)
resp = session.post(url=url, data=data, headers=headers)

content = resp.text

with open('xxx.html', 'w', encoding='utf-8') as fp:
    fp.write(content)
```



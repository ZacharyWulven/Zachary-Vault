---
layout: post
title: Python-爬虫入门-01
date: 2023-07-20 16:45:30.000000000 +09:00
categories: [Python, 爬虫]
tags: [Python, 爬虫]
---

# urllib
## 1 urllib 基本使用 

```python
# 使用 urllib 获取指定 url 源码

import urllib.request

# 定义 url
url = ''
print(url)

# 模拟浏览器向服务器发送请求
response = urllib.request.urlopen(url)

# 获取响应中的页面源码
# read 方法返回的是字节形式的二进制数据
# 二进制 --> 字符串，称为解码 decode('编码格式')
content = response.read().decode('utf-8')
print(content)
```

## 2 urllib 一个类型、六个方法
* 类型：response 是 HTTPResponse 类型
* 方法
1. read
2. readline
3. readlines
4. getcode
5. geturl
6. getheaders


```python

import urllib.request

# 定义 url
url = ''

# 模拟浏览器向服务器发送请求
response = urllib.request.urlopen(url)

# urllib 一个类型、六个方法
# response 是 HTTPResponse 类型
print(type(response))

# 方法 1：read，按照一个字节一个字节去读
#content = response.read()

# 读 5 个字节
# content = response.read(5)

# 方法 2：读取一行
# content = response.readline()

# 方法 3：按行读，直到没有数据
# content = response.readlines()
# print(content)

# 方法 4：返回状态码，如果是 200 就证明代码没有问题
print(response.getcode())

# 方法 5：返回 url 地址
print(response.geturl())

# 方法 6：获取状态信息
print(response.getheaders())
```


## 3 使用 urllib 下载

```python
import urllib.request

# 下载网页
url_page = ''

# urlretrieve 参数
# 1 url 是下载的路径
# 2 filename 是下载的文件名字
urllib.request.urlretrieve(url_page, 'page.html')

# 下载图片
jiexika = 'https://gimg2.xxx.com/image_search/src=http%3A%2F%2Fsafe-img.xhscdn.com%2Fbw1%2F8facfcf5-2108-46e1-8fb1-0773f401ab44%3FimageView2%2F2%2Fw%2F1080%2Fformat%2Fjpg&refer=http%3A%2F%2Fsafe-img.xhscdn.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1693067282&t=a45fb05d629f0faef9b486886e021f8c'
urllib.request.urlretrieve(url=jiexika, filename='jiexika.jpg')
```

## 4 请求对象定制
* 解决 UA 反爬

```python
import urllib.request

url = ''

# url 组成
# http/https   www.hogetsu.com   80/443                 #
# 协议          主机               端口号    路径   参数    锚点
# http 80
# https 443
# mysql 3306
# oracle 1521
# redis 6379
# mongodb 27017


# UA 即 UserAgent，它是一种特殊的字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器内核等
# 解决 UA 反爬
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}

# 请求对象的定制
# 由于 urlopen 的参数没有字典类型，所以需要构建一个 request 对象
# Note 因为参数顺序问题，不能直接写 url 和 header，要使用参数关键字
request = urllib.request.Request(url=url, headers=headers)
response = urllib.request.urlopen(request)
content = response.read().decode('utf-8')
print(content)
```

> 
{: .prompt-info }


